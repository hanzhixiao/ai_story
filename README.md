# grandma 讲故事的地方

grandma是一个前后端分离的AI故事创作APP，用户可以与AI合作，提供思路，和AI商讨故事大纲，让AI为他写下完整的故事

项目整体采用前后端分离开发
后端使用golang作为主要开发语言
前端使用React + Vite开发

# 根据feature进行开发时，随时将修改记录到前后端的README中，保持文档详细，准确

## v0.1 Features

### 前端：
- ✅ 类似GPT的页面UI风格，以打字机样式展示后端发送的大模型响应
- ✅ 可以自由选择多种模型，并将用户输入发送给后端
- ✅ 流式接收AI响应，实时显示
- ✅ 用户说的话在右侧，大模型返回的内容在左侧，并用色块区分
- ✅ 前端在请求时仅携带本次用户请求的内容
- ✅ 简化的颜色方案：仅三种颜色（背景、用户消息框、AI消息框）
- ✅ AI响应时可输入但不能发送
- ✅ Markdown渲染：支持大模型返回的Markdown内容渲染（代码块、表格、列表等）

### 后端：
- ✅ 接入多种大模型API（OpenAI、Anthropic）
- ✅ 接收用户发送，调用大模型API
- ✅ web框架使用gin进行开发
- ✅ 将大模型的返回以流式接口返回给前端
- 针对文本场景，做出如下处理：
    - 用户的每个对话有独立的**对话ID**
    - 对话中用户的每一段提问，用户的每一段发言，都有*独立的***文档ID**
-   采用微服务架构，后端拆分为如下模块：
    - 对话模块：接收用户请求，将用户请求传递给大模型，并用流式输出返回大模型响应
    - 对话列表模块：接收用户请求，返回用户的历史对话列表
    - 文档管理模块
    - 对话管理模块

## v0.2 Features

### 前端
- ✅ 输入框样式优化：将模型选择和输入栏放在一起
    - 在未开启对话时，输入栏在屏幕中部展示，上面写一行字："开启一个故事"，整体居中
    - 开启对话后，输入栏在页面底部展示
    - 输入栏整体为圆角设计，下拉框也为圆角
- ✅ 页面配色优化：要求整体协调，高级，不突兀
    - 使用半透明背景和毛玻璃效果（backdrop-filter）
    - 统一的颜色方案：使用 rgba 透明度，提升视觉层次
    - 优化的滚动条样式：半透明设计
    - 消息气泡：用户消息使用绿色半透明，AI消息使用深灰色半透明，并添加阴影效果
- ✅ 页面样式优化：对话列表支持隐藏和展开
    - 隐藏后在左侧展示一个小边栏（40px宽），带有展开按钮
    - 展开按钮悬停时有动画效果（颜色变化、轻微位移）
    - 优化对话项样式：圆角、间距、悬停效果
    - 使用 cubic-bezier 缓动函数的过渡动画
- ✅ 支持新对话按钮，旧对话会作为一项展示在历史对话栏中
- ✅ 对话ID管理：发送消息前自动获取或创建对话ID
- ✅ 历史对话加载：点击历史对话可加载完整的对话内容
    - 历史对话消息按顺序展示（按照 created_at ASC 排序）
    - 历史对话消息一次性完整显示，不使用打字机效果
    - 新消息发送时使用打字机效果
- ✅ 对话列表刷新优化：只在必要时刷新列表（新对话第一次发送消息时更新标题）
- ✅ 移除欢迎消息：删除"欢迎使用 Grandma"和"AI故事创作助手，让我们开始创作吧！"的欢迎消息

### 后端
- ✅ 对话列表模块
    - 接收前端的新对话请求，返回给前端一个唯一的对话ID
    - 在用户发起请求或者点击新对话时，首先请求对话列表模块，得到当前对话的对话ID
    - 对话列表按 `updated_at DESC` 排序，最新对话排在最前
- ✅ 文档管理模块
    - 后台对话模块接收到大模型的返回时，首先为该文档生成一个文档ID
    - 接收到大模型的返回，不光要将返回传递给前端，还需要将返回根据文档ID保存在数据库内，由于返回是流式的，需要不断将返回append到文档中
    - 文档列表按 `created_at ASC` 排序，确保消息按对话顺序展示
- ✅ 接入数据库，支持对话信息的存储和文档的存储
    - 对话信息包含当前对话所有的文档ID，按照先后顺序排列（逗号分隔）
    - 文档信息包含文档内容，文档时间，文档角色，所属对话ID
    - 使用 SQLite + GORM 进行数据持久化
- ✅ 流式文档保存：在流式响应过程中，每100个字符更新一次数据库
- ✅ 对话上下文管理：从数据库加载历史消息作为上下文发送给大模型
- ✅ API参数绑定修复：修复文档列表API的查询参数绑定问题（添加 `form` 标签）

## v0.3 Features

### 前端

- 增加对对话进行重命名的按钮
- 点击新对话时，
    判断用户是否为当前对话命名过，若没有，则将旧对话的所有用户输入作为一个列表发送给后端的智能命名接口，用后端返回的名字调用后端的对话列表模块的重命名接口为旧对话命名

### 后端

- 对话列表模块
    - 重命名接口：支持对对话进行重命名
    - 在用户发起请求或者点击新对话时，首先请求对话列表模块
        - 后台将用户所有的请求发送给大模型，让大模型总结一个标题，将标题返回。 
        - 为新对话分配一个对话ID

## v0.3.1 Features

### 前端

- 增加对话删除按钮，在重命名按钮右侧
- 点击新对话时，
    判断用户是否为当前对话命名过，若没有，则将旧对话的所有用户输入作为一个列表发送给后端的智能命名接口，用后端返回的名字调用后端的对话列表模块的重命名接口为旧对话命名
- /api/documents?conversation_id优化：
    - 增加翻页逻辑：请求时携带当前页面所有文档中最早的文档ID A
    - 首先请求后台GetByConversationID接口，获取当前对话中，比参数中文档ID A更早的十个文档ID
    - 并发请求后台获取文档模块，拉取上一页的文档并按顺序渲染
- bug修改：用户点击新对话时，若用户当前已经在一个旧对话中且这个对话为默认标题，则将旧对话用户的全部请求发送给大模型，让大模型总结一个标题，用这个返回的标题作为旧对话的标题

### 后端

- GetByConversationID函数优化
    - 增加翻页逻辑：返回比请求中文档ID A更早的十个文档
    - 不直接返回文档内容，数据隔离，对话列表模块仅涉及对话模块，文档查询由文档模块进行
- bug修改：用户点击新对话时，若用户当前已经在一个旧对话中且这个对话为默认标题，则将旧对话用户的全部请求发送给大模型，让大模型总结一个标题，用这个返回的标题作为旧对话的标题

## v0.3.2 Features

### 前端

- 样式优化
    - AI返回框的下方距离文字有点过宽
    - 对话列表的宽度可以通过鼠标拖动调整
    - 当用户为对话命名了一个很长的名字，可以鼠标hover在对话项上方，查看对话名
    - 删除对话弹出的确定框需要一个好看的在当前屏幕居中的提示框，同时用户可以勾选不再提醒

### 后端

- 请求优化：在请求AI时不需要带上当前对话之前的全部文档

## v0.3.3 Features

### 前端

- 逻辑优化：
    - 当用户在当前对话时，用户再点击当前对话，不发起/api/documents请求
- 体验优化：
    - 用户在向上翻页时不用手动点击加载，只需要向上滑动滚轮，会展示一个加载中的图案，加载好后可以无缝继续向上滑动，加载出历史对话不会影响用户浏览的位置

## v0.3.4 Features

- 对话展示
    - 第一次对话时
        1.请求对话列表模块，获得这个对话的最新10个文档的ID
        2.**并发**请求文档管理模块，同时发送10个请求，每个请求获取一个文档的详细信息

## v0.3.5 Features

### 前端

- ✅ 体验修改
  - 用户在切换对话时，检查用户旧对话的名字，如果用户没有为旧对话进行自定义命名，则将旧对话用户的全部请求发送给大模型，让大模型总结一个标题，用这个返回的标题作为旧对话的标题
  - 实现方式：
    - 在 `handleSelectConversation` 中，切换对话前先检查旧对话是否有默认标题（"新对话"）
    - 如果有默认标题，调用 `getAllUserInputsForConversation` 获取旧对话的所有用户输入
    - 通过分页方式获取所有文档（每次100条），收集所有用户输入
    - 调用 `/api/conversations/generate-title` 接口生成标题
    - 使用生成的标题重命名旧对话

## v0.3.6 Features


## 快速开始

### 后端

1. 进入后端目录
```bash
cd backend
```

2. 安装依赖
```bash
go mod download
```

3. 配置环境变量
创建 `.env` 文件，配置API密钥：
```env
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
PORT=8080
```

4. 运行服务器
```bash
go run main.go
```

后端将在 `http://localhost:8080` 启动

### 前端

1. 进入前端目录
```bash
cd fronend
```

2. 安装依赖
```bash
npm install
```

3. 启动开发服务器
```bash
npm run dev
```

前端将在 `http://localhost:3000` 启动

## 项目结构

```
grandma/
├── backend/              # 后端代码（Golang + Gin）
│   ├── config/           # 配置管理
│   ├── database/          # 数据库初始化
│   ├── models/            # 数据模型
│   ├── repository/        # 数据访问层（Repository模式）
│   ├── services/          # 业务逻辑（大模型API接入）
│   ├── modules/           # 微服务模块
│   │   ├── chat/          # 对话模块
│   │   ├── conversation/  # 对话管理模块
│   │   ├── conversation_list/  # 对话列表模块
│   │   └── document/      # 文档管理模块
│   ├── utils/             # 工具函数（ID生成等）
│   └── main.go            # 入口文件
├── fronend/               # 前端代码（React + Vite）
│   ├── src/
│   │   ├── components/    # React组件
│   │   │   ├── ChatContainer.jsx      # 聊天容器
│   │   │   ├── ConversationHistory.jsx # 对话历史
│   │   │   ├── EnhancedInputArea.jsx   # 增强输入框
│   │   │   ├── MarkdownRenderer.jsx    # Markdown渲染器
│   │   │   ├── Message.jsx              # 消息组件
│   │   │   └── MessageList.jsx         # 消息列表
│   │   ├── App.jsx        # 主应用
│   │   └── main.jsx       # 入口文件
│   └── package.json
└── README.md
```

## 使用说明

1. 确保后端和前端都已启动
2. 在浏览器访问 `http://localhost:3000`
3. 在输入框上方的下拉框中选择要使用的大模型
4. 在输入框中输入你的想法或问题
5. 按 Enter 或点击发送按钮
6. AI的响应将以打字机效果逐字显示
7. 点击左侧历史对话可以查看之前的对话记录
8. 历史对话消息会一次性完整显示，不使用打字机效果

## 支持的模型

- **OpenAI**: GPT-3.5 Turbo
- **Anthropic**: Claude 3.5 Sonnet

## 技术特性

### 前端技术栈
- **React 18** - UI框架
- **Vite** - 构建工具
- **react-markdown** - Markdown渲染
- **remark-gfm** - GitHub风格Markdown支持

### 后端技术栈
- **Golang** - 主要开发语言
- **Gin** - Web框架
- **GORM** - ORM框架
- **SQLite** - 数据库
- **Server-Sent Events (SSE)** - 流式响应

### 核心功能
- **流式响应**：实时显示AI响应，提升用户体验
- **打字机效果**：新消息使用打字机效果，历史对话一次性显示
- **Markdown渲染**：支持代码块、表格、列表等Markdown语法
- **对话管理**：支持多对话管理，每个对话有独立的ID
- **上下文管理**：自动加载历史消息作为上下文发送给大模型
- **数据持久化**：所有对话和消息都保存在数据库中

## 开发计划

- [x] 历史对话记录
- [ ] 故事大纲生成
- [ ] 故事保存和导出
- [ ] 更多大模型支持
- [ ] 对话搜索功能
- [ ] 对话导出功能
